[
  {
    "path": "posts/2020-09-22-exporting-editable-ggplot-graphics-to-powerpoint-with-officer-and-purrr/",
    "title": "Exporting editable ggplot graphics to PowerPoint with officer and purrr",
    "description": "What, why, how, when, and who",
    "author": [
      {
        "name": "Shannon Pileggi",
        "url": {}
      }
    ],
    "date": "2020-09-22",
    "categories": [],
    "contents": "\nTable of Contents\nTL; DR\nWhat is an editable PowerPoint graphic?\nWhy should I create it?\nHow do I create it?\nWhen should I do this more efficiently?\nWho should do the editing?\nLimitations\nSummary\nAppendix\nAcknowledgments\nTL; DR\nThe officer and rvg packages can be used to create PowerPoint slides with editable ggplot graphics. Skip to creating a single PowerPoint slide or to efficiently exporting multiple PowerPoint graphics with purrr.\nWhat is an editable PowerPoint graphic?\nAn editable PowerPoint graphic that is created within PowerPoint consists of two sets of editable components:\nVarious features of the graphic are editable, including items like size, color, and font (see Gif 1).\nThe data behind the graphic are editable (see Gif 2). This means that you can open the table linked to the chart and manually edit it in order to alter the data displayed in the graphic.\nAn editable PowerPoint graphic constructed in R through the officer + rvg functions described here produce vector graphics (i.e., shapes). This permits editing various features of the graphic (e.g., color, size), but not the data behind it (no linked table is created).\nWhy should I create it?\nIn my line of work, the primary deliverable is a PowerPoint slide deck. When creating an R graphic for a slide deck, I could export the graphic as an image (like a .png) to be inserted into PowerPoint, or I can export the graphic directly to an editable PowerPoint slide. Both of these options have pros and cons.\nFeature\nPowerPoint editable graphic\nImage (e.g., .png)\nEditability\nüëç\nüëé\nResizing\nüëé\nüëç\nData table\nüëé\nüëé\nThe editable PowerPoint graphic allows for direct editing in PowerPoint, but re-sizes poorly when done manually within PowerPoint. A .png image does not allow for direct editing within PowerPoint, but does nicely retain image ratios when re-sizing. Lastly, neither method produces a linked data table behind the graphic for editing.\nHow do I create it?\n\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(glue)\nlibrary(officer)\nlibrary(rvg)\nlibrary(viridis)\n\nFirst, let‚Äôs create a quick graphic for demonstration purposes using ggplot2::diamonds. We subset the data on specific values of color and clarity and produce a scatter plot showing the relationship between price and carat.\n\n\np <- diamonds %>% \n  filter(color == \"D\" & clarity == \"I1\") %>% \n  ggplot(aes(x = carat, y = price, color = cut)) +\n    geom_point() +\n    theme_minimal() +\n    ggtitle(\"Color: D; Clarity: I1\")\n\n\n\np\n\n\nIn order to export this graphic to an editable PowerPoint slide, first use the rvg package to convert the object to class dml (required to make graphic editable).\n\n\np_dml <- rvg::dml(ggobj = p)\n\nThen export the dml object to a PowerPoint slide with officer.\n\n\n# initialize PowerPoint slide ----\nofficer::read_pptx() %>%\n  # add slide ----\n  officer::add_slide() %>%\n  # specify object and location of object ----\n  officer::ph_with(p_dml, ph_location()) %>%\n  # export slide -----\n  base::print(\n    target = here::here(\n      \"_posts\",\n      \"2020-09-22-exporting-editable-ggplot-graphics-to-powerpoint-with-officer-and-purrr\",\n      \"slides\",\n      \"demo_one.pptx\"\n    )\n  )\n\nHere is a screen shot of the resulting PowerPoint slide, or you can download demo_one.pptx.\n\nWhen should I do this more efficiently?\nThere are 56 combinations of color and clarity in the diamonds data set; naturally, your colleague wants all 56 plots (at least for the appendix of the report üòÇ). So we definitely want an efficient way to do this!\nAutomate many plots\nThis work follows up on blog posts by Laurens Geffert, Len Kiefer, and Bruno Rodrigues, which were fantastic resources to help me get started. The officer package enacted changes in version 0.3.11(?) which necessitate updates to these methods (see Acknowledgements). In addition, Amber Thomas outlined a purrr work flow that resonates with me.\nI start with a table outlining the 56 combinations of color and clarity.\n\n\n# tibble of all possible combinations ----\ndiamonds_grid <- diamonds %>% \n  count(color, clarity) %>% \n  # for mapping, we need input values to be character ----\n  mutate_all(as.character)\n\n\n\n# view values of grid ----\ndiamonds_grid\n\n# A tibble: 56 x 3\n   color clarity n    \n   <chr> <chr>   <chr>\n 1 D     I1      42   \n 2 D     SI2     1370 \n 3 D     SI1     2083 \n 4 D     VS2     1697 \n 5 D     VS1     705  \n 6 D     VVS2    553  \n 7 D     VVS1    252  \n 8 D     IF      73   \n 9 E     I1      102  \n10 E     SI2     1713 \n# ... with 46 more rows\n\nThen I create a function that produces the plot for any given combination of color and clarity. As ggplot produces plots for the available data, there are some additional updates to this function to maintain consistency across all plots. We use a named color vector to create consistency in plotting colors across all plots, in addition to enforcing consistency in the x and y plotting ranges.\n\n\n# named vector for the colors assigned to cut ----\n# values are the colors assigned ----\ncolor_cut <- viridis::viridis(5) %>% \n  # assign levels of cut as names to colors ----\n  rlang::set_names(levels(diamonds[[\"cut\"]]))\n\n\n\n# view named color vector ----\ncolor_cut\n\n       Fair        Good   Very Good     Premium       Ideal \n\"#440154FF\" \"#3B528BFF\" \"#21908CFF\" \"#5DC863FF\" \"#FDE725FF\" \n\n\n\n# function to produce scatter plot of carat and price for given values of color and clarity ----\nplot_diamonds <- function(this_color, this_clarity){\n  diamonds %>% \n    filter(color == this_color & clarity == this_clarity) %>% \n    ggplot(aes(x = carat, y = price, color = cut)) +\n      geom_point() +\n      theme_minimal() +\n      # maintain consistent plot ranges ----\n      xlim(range(diamonds[[\"carat\"]])) +\n      ylim(range(diamonds[[\"price\"]])) +\n      # maintain consistent colors for cut ----\n      # show all values of cut in legend, regardless if appear in this plot ----\n      scale_color_manual(values = color_cut, drop = F) +\n      # title indicates which combination is plotted ----\n      ggtitle(glue::glue(\"Color: {this_color}; Clarity: {this_clarity}\")) \n\n}\n\nNext I utilize the plot_diamonds function with purrr to create a list with 56 ggplot objects representing all combinations of color and clarity.\n\n\ndiamonds_gg <- purrr::map2(\n  # first argument to plot_diamonds function ----\n  diamonds_grid[[\"color\"]],\n  # second argument to plot_diamonds function ----\n  diamonds_grid[[\"clarity\"]],\n  # function to map ----\n  plot_diamonds\n)\n\nExport many plots\nTo export these, I use two helper functions. The first function, create_dml, converts the ggplot objects to dml objects.\n\n\ncreate_dml <- function(plot){\n  rvg::dml(ggobj = plot)\n}\n\nApply this function to the list of ggplot objects to create a list of dml objects with the same dimension.\n\n\ndiamonds_dml <- purrr::map(diamonds_gg, create_dml)\n\nThe second function automates exporting all slides to PowerPoint, with some additional options to specify the position and size (inches) of the graphic. The default size (9in x 4.95in) produces a graphic that fills a standard sized slide.\n\n\n# function to export plot to PowerPoint ----\ncreate_pptx <- function(plot, path, left = 0.5, top = 1, width = 9, height = 4.95){\n  \n    # if file does not yet exist, create new PowerPoint ----\n    if (!file.exists(path)) {\n        out <- officer::read_pptx()\n    }\n    # if file exist, append slides to exisiting file ----\n    else {\n        out <- officer::read_pptx(path)\n    }\n  \n    out %>% \n      officer::add_slide() %>% \n      officer::ph_with(plot, location = officer::ph_location(\n        width = width, height = height, left = left, top = top)) %>% \n      base::print(target = path)\n}\n\nNote that this function opens and closes PowerPoint for each slide created, so more slides will take longer to export. This particular set of graphics took ~6 minutes to export due to the number of slides and the number of points on some slides üò¨ (which is longer than usual for my typical applications).\n\n\npurrr::map(\n  # dml plots to export ----\n  diamonds_dml, \n  # exporting function ----\n  create_pptx, \n  # additional fixed arguments in create_pptx ----\n  path = here::here(\n    \"_posts\", \n    \"2020-09-22-exporting-editable-ggplot-graphics-to-powerpoint-with-officer-and-purrr\",\n    \"slides\", \n    \"demo_many.pptx\"\n    )\n  )\n\nHere is a screen shot of the resulting PowerPoint slide, or you can download demo_many.pptx.\n\nWho should do the editing?\nNow that you have editable PowerPoint slides, you have two parties capable of editing the graphics: (1) the R developer, and (2) the collaborator.\nThe R developer should do further slide editing when:\nedits are universal (i.e., reduce size of all plots to 6in x 3in).\nedits are data driven (i.e., represent all points where carat exceeds a value of 3 as a star)\nThe collaborator should do further slide editing when:\nedits are bespoke (i.e.¬†Bob wants to see slide 25 in bold for the marketing team)\nedits are beyond the budget (i.e., super custom axis adornment)\nLimitations\nWhile the graphics exported to PowerPoint from R are editable, they do have limitations compared to graphics created within PowerPoint.\nAs previously mentioned, there is no linked data table behind the graphics, which can be unnerving for a colleague who wants to quality check the figure (I often export labeled and unlabeled versions of figures for this).\nThe points are not naturally grouped features as they would be for graphics created within PowerPoint. This means that if your colleagues wants to change the shade of yellow for the ideal cut diamonds they would have to click on each and every single yellow point in all slides (see Gif 3 for preview of what the slide looks like when you click around).\nSummary\nEditable PowerPoint ggplot graphics created through officer + rvg + purrr can be a great way to provide your colleague with fantastic graphics while still allowing them to refine the graphics with their own finishing touches. Do expect a lot of iteration on the graphic to get it as close as possible to their needs before you hit that final send on the PowerPoint deck.\nAppendix\nGif 1\nDemonstration of editable features in graphic created within PowerPoint. Notice that the points are automatically grouped together. Go back to What is an editable PowerPoint graphic?.\n\nGif 2\nDemonstration of editable data table behind graphic created within PowerPoint. Go back to What is an editable PowerPoint graphic?.\n\nGif 3\nDemonstration of editing title and single point color in graphic exported to PowerPoint by rvg + officer (notice points are not grouped). Go back to Limitations.\n\nAcknowledgments\nThe create_pptx function was modified from Bruno Rodrigues. My colleague Tom Nowlan figured out the function updates for officer::ph_with (formerly officer::ph_with_vg) to export figures to a specific size and location. Thumbnail artwork was adapted from @allison_horst.\n\n\n",
    "preview": "posts/2020-09-22-exporting-editable-ggplot-graphics-to-powerpoint-with-officer-and-purrr/data_cowboy_officer.png",
    "last_modified": "2020-10-07T20:51:39-04:00",
    "input_file": {},
    "preview_width": 678,
    "preview_height": 382
  },
  {
    "path": "posts/2020-09-07-introducing-the-rstudio-ide-and-r-markdown/",
    "title": "Introducing RStudio and R Markdown",
    "description": "Gettin' giffy wit it.",
    "author": [
      {
        "name": "Shannon Pileggi",
        "url": {}
      }
    ],
    "date": "2020-09-07",
    "categories": [],
    "contents": "\nTable of Contents\nTL; DR\nBackground\nCustomizing the interface\nAdjusting panels\nRe-arrange panels\nRecover lost panels\nFont size/resolution\nPersonalization\nMargin column\n\nR Markdown\nOpening a new R Markdown\nKnitting an R Markdown\nPreview an R Markdown\nPersonalizing R Markdown\nInserting/splitting code chunks\nChunk anatomy\nChunk names\nChunk execution\nChunk options\n\nR Markdown Troubleshooting\nYAML error\nChunk error\nChunk error for duplicate chunk name\nLayout error\nR code error\n\nThe end\nAcknowledgments\nTL; DR\nRStudio has some wonderful features! Here are some tips and tricks for new learneRs to get started with regards to customizing your interface, getting started with R Markdown, and a bit of troubleshooting.\nBackground\nGif‚Äôs were captured in May 2019, likely with RStudio version 1.2.1335-1. Keyboard shortcuts are for Windows users, Mac users may differ. For Windows users, I also recommend changing your default settings to show file extensions.\nAnd if you are not familiar with it, please allow me introduce you to Will Smith‚Äôs 1998 hit ‚ÄúGettin‚Äô Jiggy Wit It.‚Äù üéµNa na na na na na na nana üéµ\nCustomizing the interface\nAdjusting panels\n\nRe-arrange panels\nTools -> Global Options -> Panel Layout\n\nRecover lost panels\n\nFont size/resolution\nView -> Zoom in / Zoom out / Actual size\n\nPersonalization\nTools -> Global Options -> Appearance\n\nMargin column\nTools -> Global Options -> Code -> Display -> Show margin -> Margin column 80\nConsider placing a margin column at 80 characters as a reminder for code formatting. Keeping code within 80 characters can make it easier to read when switching displays or sharing code.\n\nR Markdown\nOpening a new R Markdown\nFile -> New file -> R Markdown ¬†¬† or ¬†¬† -> R Markdown\n\nKnitting an R Markdown\n\nPreview an R Markdown\n\nPersonalizing R Markdown\n\nInserting/splitting code chunks\n ¬†¬† or ¬†¬† Ctrl + Alt + I\n\nChunk anatomy\n\nChunk names\nChunk names allow you to quickly navigate code, automatically name figures, and troubleshoot errors. Chunk names must be unique! If no name is provided, a default numbered chunk name will be assigned.\n\nChunk execution\n ¬†¬† or ¬†¬† Ctrl + Enter\n\nChunk options\n\nR Markdown Troubleshooting\nYAML error\n\nChunk error\n\nChunk error for duplicate chunk name\n\nLayout error\nLet your markdown breathe! If something doesn‚Äôt look right, try adding white space.\n\nR code error\n\nThe end\n\n\nAcknowledgments\nThumbnail artwork adapted from @allison_horst.\nThe phrase IDE was removed from the title and body of this post on Sep.¬†8, 2020 per @TrashBirdEcol‚Äôs suggestion.\n\n\n",
    "preview": "posts/2020-09-07-introducing-the-rstudio-ide-and-r-markdown/introducing_resize2.png",
    "last_modified": "2020-10-07T20:51:39-04:00",
    "input_file": {},
    "preview_width": 473,
    "preview_height": 371
  },
  {
    "path": "posts/2020-08-30-a-job-interview-presentation-inspired-by-the-r-community/",
    "title": "A job interview presentation inspired by the R community",
    "description": "How #tidytuesday and twitter helped me secure a job offer",
    "author": [
      {
        "name": "Shannon Pileggi",
        "url": {}
      }
    ],
    "date": "2020-08-30",
    "categories": [],
    "contents": "\nTable of Contents\nTL; DR\nBack up\nFormulation\nFortuitous tweets\nWhat I did\nResults\nAcknowledgements\n\nTL; DR\nI utilized resources from #tidytuesday, twitter, and blog posts to create a job interview presentation that provided insights on my prospective employer while showcasing my analytics capabilities.\nBack up\nWhen I was told that my interview at Adelphi Research would involve a presentation, I was pretty happy. A presentation allows the candidate to highlight their strengths, and, after being a college professor for six years, I was confident in my public speaking. The specific presentation instructions were:\n\nThis can be any 20 minute presentation you‚Äôd like to share with the team; our recommendation is that it focuses on Market Research, is something innovative, and something that you‚Äôre particularly proud of!\n\nIt was also briefly mentioned in the phone screening that the analytics group with whom I was interviewing was just beginning to develop shiny applications.\nFormulation\nThen I faced the dilemma of what to actually present. I wanted to shine as a candidate, but my previous academic experience was tangential to this industry. I took their instructions to heart and decided to create something of which I was truly proud. I developed a project with three goals in mind:\nLearn about my prospective employer.\nCultivate my nascent tidyverse skills.\nInvest in new analytic methods and coding techniques that could serve future me.\nFrom there, I had to figure out what I would actually present.\nFortuitous tweets\nThis was winter 2018, which also happened to be the inaugural year of #tidytuesday. Prompted by David Robinson‚Äôs screencast analyzing medium articles with tidytext, I was inspired to apply the same principles of text analysis to my prospective employer‚Äôs twitter account.\n\n\nIn this week's #tidytuesday screencast, I use tidytext to analyze what titles get claps on Medium posts. Practical guides on tensorflow/keras are the hottest, words like ‚Äúmarketing‚Äù, ‚Äútrends‚Äù and ‚Äúindustry‚Äù don't get you far https://t.co/oNhZm40mpW #rstats pic.twitter.com/cxYO2MIIqz\n\n‚Äî David Robinson (@drob) December 4, 2018\n\nAs I started to create my presentation, I was also concerned with the actual format / deliverable for the presentation. I knew I wanted to create something in R, but I was not quite sure which direction to go. I tweeted an #rstats plea for advice and was inspired by Emily Riederer‚Äôs suggestion to use a flexdashboard for the presentation.\n\n\nIf you‚Äôre having trouble with xaringan, storyboards in flexdashboqrd can also make pretty nice presentations depending on the type of content / message you are trying to convey https://t.co/IC3moe01v0\n\n‚Äî Emily Riederer (@EmilyRiederer) December 12, 2018\n\nWhat I did\nAfter many hours at the computer, several re-watches of David Robinson‚Äôs screencast, and a lot of research on R functions and analytic methods, I created a presentation about my prospective employer based on trends in their twitter account between 2009 (account start date) and 2018 (interview date). Here are the packages that I used, alongside their purpose with links to code on github:\nrtweet: retrieve tweets from @AdelphiResearch.\ndplyr, forcats, lubridate, stringr, and purrr: create new variables with regards to tweet descriptors and hashtag themes; summarize trends in top hashtags over time\nggplot2: exploratory visualization of tweet frequency, trends in likes and re-tweets per tweet, and trends in hashtag themes over time\ntidytext: transform tweet words to analyzable tokens; prepare words for modeling\nwidyr, igraph, ggraph: network analysis of common hashtag themes and tweet text\nglmnet: lasso model to assess word associations with likes and retweets\nshiny: develop shiny apps to search tweets and explore the network analyses\nflexdashboard: assemble it all in a presentation\nYes, it was a lot! Especially because the tidyverse, pulling tweets, text analysis, network analysis, lasso models, flexdashboards, and shiny apps were all very new to me.\nResults\nI hosted my presentation and the two shiny applications on shinyapps.io, and I made my code publicly available on github.\nLink \nPreview \nInterview presentation\n\nShiny app for tweet look up\n\nShiny app for network analysis\n\nCode on github\n\nIn the end, I got the job! Along the way, I gleaned insights about the values and industry of my prospective employer, empowering me throughout the interview process. Additionally, my interviewers enjoyed the external data-driven view of their company‚Äôs tweets (despite, or perhaps because of, the fact that none of them were actually on twitter).\nI embraced the interview as an opportunity to create my own side project to foster new skills that would serve me for other potential interviews, personal projects, or work projects. Yes, I probably could have secured a job offer with less effort, but I would have been less confident and I would have missed out on so many data and programming approaches that are now ingrained in my thought processes. And enabled by the #rstats twitter presence, the incredible packages that I used, and the numerous blog posts that I referenced, I had fun. Cheers, R! ü•Ç\nAcknowledgements\nThumbnail artwork by @allison_horst. Thanks to Megan McClintock (my sister) for feedback and suggestions.\n\n\n",
    "preview": "posts/2020-08-30-a-job-interview-presentation-inspired-by-the-r-community/welcome_to_rstats_twitter.png",
    "last_modified": "2020-10-07T20:51:39-04:00",
    "input_file": {},
    "preview_width": 2009,
    "preview_height": 1942
  },
  {
    "path": "posts/2018-12-11-stringr-4-ways/",
    "title": "Stringr 4 ways",
    "description": "Four approaches to feature engineering with regular expressions in R",
    "author": [
      {
        "name": "Shannon Pileggi",
        "url": {}
      }
    ],
    "date": "2018-12-11",
    "categories": [],
    "contents": "\nUpdate May 22, 2019: Thanks to @hglanz for noting that I could have used pull instead of the . as a placeholder.\n\n\nlibrary(tidyverse) # general use\nlibrary(titanic)   # to get titanic data set\n\nOverview\nThe Name variable in the titanic data set has all unique values. To get started, let‚Äôs visually inspect a few values.\n\n\ntitanic_train %>% \n  select(Name) %>% \n  head(10)\n\n                                                  Name\n1                              Braund, Mr. Owen Harris\n2  Cumings, Mrs. John Bradley (Florence Briggs Thayer)\n3                               Heikkinen, Miss. Laina\n4         Futrelle, Mrs. Jacques Heath (Lily May Peel)\n5                             Allen, Mr. William Henry\n6                                     Moran, Mr. James\n7                              McCarthy, Mr. Timothy J\n8                       Palsson, Master. Gosta Leonard\n9    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)\n10                 Nasser, Mrs. Nicholas (Adele Achem)\n\nIn this brief print out, each passenger‚Äôs title is consistently located between , and .. Luckily, this holds true for all observations! With this consistency, we can somewhat easily extract a title from Name. Depending on your field, this operation may be referred to something along the lines of data preparation or feature engineering.\nTL; DR\nApproach\nFunction(s)\nRegular expression(s)\n1\nstr_locate + str_sub\n\",\" + \"\\\\.\"\n2\nstr_match\n\"(.*)(, )(.*)(\\\\.)(.*)\"\n3\nstr_extract + str_sub\n\"([A-z]+)\\\\.\"\n4\nstr_replace_all\n\"(.*, )|(\\\\..*)\"\nRead on for explanations!\nOverview of regular expressions\nRegular expressions can be used to parse character strings, which you can think of as a key to unlock string patterns. The trick is identify the right regular expression + function combination. Let‚Äôs demo four ways to tackle the challenge utilizing functions from the stringr package; each method specifies a different string pattern to match.\n\n\nlibrary(stringr)\n\nExtracting title from name\nFirst approach\nICYMI, the double bracket in titanic_train[[\"Name\"]] is used to extract a named variable vector from a data frame, which has some benefits over the more commonly used dollar sign (i.e., titanic_train$Name). Now onward.\nThe str_locate function produces the starting and ending position of a specified pattern. If we consider the comma to be a pattern, we can figure out where it is located in each name. Here, the starting and ending value is the same because the comma is only one character.\n\n\ntitanic_train[[\"Name\"]] %>% \n  str_locate(\",\") %>%\n  head()\n\n     start end\n[1,]     7   7\n[2,]     8   8\n[3,]    10  10\n[4,]     9   9\n[5,]     6   6\n[6,]     6   6\n\nKnowing this, we can identify the positions of the comma and the period and then extract the text in between. Some notes here:\nBecause str_locate function returns a matrix, we use . as a placeholder in .[,1] to access the first column of values.\nBecause . is a special character in regular expressions, we use the double backslash in \"\\\\.\" to escape it.\n\n\ncomma_pos <- titanic_train[[\"Name\"]] %>% \n  str_locate(\",\") %>% \n  .[,1]\n\nperiod_pos <- titanic_train[[\"Name\"]] %>% \n  str_locate(\"\\\\.\") %>% \n  .[,1]\n\nNow we can use str_sub to extract substrings from the character vector based on their physical position. To exclude the punctuation and white space, we can add two to the comma position and subtract one from the period position to get the title only.\n\n\ntitanic_train[[\"Name\"]] %>% \n  str_sub(comma_pos + 2, period_pos - 1) %>% \n  head()\n\n[1] \"Mr\"   \"Mrs\"  \"Miss\" \"Mrs\"  \"Mr\"   \"Mr\"  \n\nSuper!\nSecond approach\nThe str_match function creates a character matrix for each group matched in the specified pattern. With the correct regular expression, str_match returns the complete match in addition to each matched group. Here‚Äôs a quick example:\n\n\n# ----------5 groups-->>>----1---2---3----4---5----                      \nstr_match(\"XXX, YYY. ZZZ\", \"(.*)(, )(.*)(\\\\.)(.*)\")\n\n     [,1]            [,2]  [,3] [,4]  [,5] [,6]  \n[1,] \"XXX, YYY. ZZZ\" \"XXX\" \", \" \"YYY\" \".\"  \" ZZZ\"\n\nLet‚Äôs break down this regular expression pattern.\nThe parentheses () indicate a grouping\nThe 2nd grouping (, ) only has one modification from the pattern used in the first example - here we include a space after the comma.\nThe 4th grouping (\\\\.) remains unchanged from the first example.\nin the 1st, 3rd, and 5th grouping (.*)\nThe period . means any character\nThe asterisk * means matches at least 0 times\n\nTo execute this, we‚Äôll grab the 4th column to catch our title.\n\n\ntitanic_train[[\"Name\"]] %>% \n  str_match(\"(.*)(, )(.*)(\\\\.)(.*)\") %>%\n  .[,4] %>% \n  head()\n\n[1] \"Mr\"   \"Mrs\"  \"Miss\" \"Mrs\"  \"Mr\"   \"Mr\"  \n\nAll right, we got it again!\nThird approach\nLastly, let‚Äôs use the str_extract function to extract matching patterns. This seems like what we wanted to do all along!\n\n\ntitanic_train[[\"Name\"]] %>% \n  str_extract(\"([A-z]+)\\\\.\") %>%\n  head()\n\n[1] \"Mr.\"   \"Mrs.\"  \"Miss.\" \"Mrs.\"  \"Mr.\"   \"Mr.\"  \n\nLet‚Äôs break down this regular expression:\nHere, the bracket []specifies a list of permitted characters.\nInside the bracket, we specify strings that consist of both upper and lower case letters with A-z.\nThe + outside the bracket signifies ‚Äúmatch at least one time‚Äù, i.e., grab all the letters.\nFinally, ending in \\\\. indicates that our pattern should end in period.\nPutting it all together, this pattern translates to ‚Äúgrab all upper case and lower case letters immediately preceeding a period.‚Äù\nThis pattern is a bit more sophisticated to compose than the previous ones, but it gets right to the point! This last effort does end in a period, whereas the others do not. If we wanted to remove the period for consistency, we could use str_sub with the end argument to specify the position of the last character.\n\n\ntitanic_train[[\"Name\"]] %>% \n  str_extract(\"([A-z]+)\\\\.\") %>%\n  str_sub(end = -2) %>%\n  head()\n\n[1] \"Mr\"   \"Mrs\"  \"Miss\" \"Mrs\"  \"Mr\"   \"Mr\"  \n\nFourth approach\nAs a last approach, we can use str_replace_all to replace all matched patterns with null character values. Here, we specify the pattern and then the replacement string.\n\n\ntitanic_train[[\"Name\"]] %>% \n  str_replace_all(\"(.*, )|(\\\\..*)\", \"\") %>%\n  head()\n\n[1] \"Mr\"   \"Mrs\"  \"Miss\" \"Mrs\"  \"Mr\"   \"Mr\"  \n\nIn this regular expression,\nThere are two groupings separated by a vertical pipe | which means ‚Äúor‚Äù.\nThe two groupings should look familar:\nThe first grouping looks for all characters preceeding a comma space.\nThe second grouping looks for all characters following a period.\n\nPutting it together, if grouping 1 or grouping 2 is satisifed then those character values are replaced with null character values.\nRe-classifying entries\nNow that we figured out how to extract the title, I‚Äôll utilize the last method and assign title as a variable to the titanic_train data set using the mutate function.\n\n\ntitanic_train <- titanic_train %>%\n  mutate(title = str_replace_all(titanic_train[[\"Name\"]], \"(.*, )|(\\\\..*)\", \"\"))\n\nNow let‚Äôs use count to get a frequency table of the titles, with the sort = TRUE option to arrange the results in descending order.\n\n\ntitanic_train %>%\n  count(title, sort = TRUE)\n\n          title   n\n1            Mr 517\n2          Miss 182\n3           Mrs 125\n4        Master  40\n5            Dr   7\n6           Rev   6\n7           Col   2\n8         Major   2\n9          Mlle   2\n10         Capt   1\n11          Don   1\n12     Jonkheer   1\n13         Lady   1\n14          Mme   1\n15           Ms   1\n16          Sir   1\n17 the Countess   1\n\nWe can see that there are several infrequent titles occuring only one or two times, and so we should re-classify them. If you want to squeeze the most juice out of your data, try to figure out the historical context and meaning of those titles to create a better classification for them. For now, let‚Äôs take the easy way out by just re-classifying them to an other group.\nFortunately, the forcats package has an awesome function that let‚Äôs us do this quickly: fct_lump. We‚Äôre using mutate again to re-classified title. The fct_lump function combines the least frequent values together in an other group, and the n = 6 option specifies to keep the 6 most common values (so the 7th value is other).\n\n\ntitanic_train %>%\n  mutate(title = fct_lump(title, n = 6)) %>%\n  count(title, sort = TRUE)\n\n   title   n\n1     Mr 517\n2   Miss 182\n3    Mrs 125\n4 Master  40\n5  Other  14\n6     Dr   7\n7    Rev   6\n\nIf you wanted to explicitly re-code the infrequent titles to something more meaningful than other, look into fct_recode.\nSuper, now title is ready to use for analysis!\n\n\n",
    "preview": "posts/2018-12-11-stringr-4-ways/table2.png",
    "last_modified": "2020-10-07T20:51:39-04:00",
    "input_file": {},
    "preview_width": 1010,
    "preview_height": 319
  },
  {
    "path": "posts/2018-11-05-welcome-to-piping-hot-data/",
    "title": "Welcome to Piping Hot Data",
    "description": "What's in a name?",
    "author": [
      {
        "name": "Shannon Pileggi",
        "url": "www.pipinghotdata.com"
      }
    ],
    "date": "2018-11-05",
    "categories": [],
    "contents": "\nSo do I have piping hot data or am I piping hot data? Let‚Äôs break it down.\nPiping Hot Data\nWow, my data is piping hot! This connotes exciting, newly released data! I can‚Äôt promise that I‚Äôll fulfill this expectation. Let‚Äôs just say that I‚Äôll talk about data occasionally, and on special occassions it might even be piping hot.\nPiping Hot Data\nHere, I am piping my elusive hot data. This is what I was really going for - an ode to the pipe in R:\n\n%>%\n\nThe pipe operator simplifies long operations by linking multiple functions simultaneously. Although the coding construct of the pipe has been floating around since the 1970‚Äôs, the floodgates didn‚Äôt open for R until 2014. I don‚Äôt know the exact date, but I do remember the first time I saw those three characters and the sea of emotions that rained down. Confusion. Curiousity. Excitement.\nIn just 4 short years, the pipe and its friends in the tidyverse have revolutionized how we code in R, to the point that you may feel illiterate at conferences if you don‚Äôt have some baseline understanding - at first. Because the beauty of the pipe is that it streamlines readability of R code, such that even if you have never done it, you can still get the gist of what is going on. So much so that believers are proselytizing ‚ÄúTeach the tidyverse to beginners‚Äù!\nLet‚Äôs lay the pipelines with a quick example using the classic iris data set. To get started, load the tidyverse library and get an overview of the data.\n\n\nlibrary(tidyverse)\nglimpse(iris)\n\nRows: 150\nColumns: 5\n$ Sepal.Length <dbl> 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4,...\n$ Sepal.Width  <dbl> 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9,...\n$ Petal.Length <dbl> 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4,...\n$ Petal.Width  <dbl> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2,...\n$ Species      <fct> setosa, setosa, setosa, setosa, setosa, seto...\n\nOur simple objective is to compute the mean Sepal.Length for each Species in the data set and then arrange the results in descending order. There are many ways to accomplish this without the tidyverse, but for the sake of side-by-side comparisons I‚Äôll demo this using tidyverse functions first without and then with piping.\n\n\narrange(\n  summarise(\n    group_by(iris, Species), \n    mean = mean(Sepal.Length)\n  ), \n  desc(mean)\n)\n\n# A tibble: 3 x 2\n  Species     mean\n  <fct>      <dbl>\n1 virginica   6.59\n2 versicolor  5.94\n3 setosa      5.01\n\nWithout using pipes, we have to read our code inside to out to understand the operations executed. Our iris data set is buried in the middle of the code, and then the operations performed of group_by, summarise, and arrange spring outward from there (reading up from iris). Now let‚Äôs try the same manipulations utilizing piping.\n\n\niris %>% \n  group_by(Species) %>% \n  summarise(mean = mean(Sepal.Length)) %>%\n  arrange(desc(mean))\n\n# A tibble: 3 x 2\n  Species     mean\n  <fct>      <dbl>\n1 virginica   6.59\n2 versicolor  5.94\n3 setosa      5.01\n\nVoil√°! It‚Äôs clear from the left side of the pipe that all manipulations are done on the iris data set, and it‚Äôs clear from the right side of the pipe that the series of operations performed are group_by, summarise, and arrange. Wow, I like the way data flow through those pipes!\nWhile the name of this blog gives an nod to the powerful pipe, the pipe isn‚Äôt going to permeate every solution to programming challenges. So here is what to expect from Piping Hot Data:\nDemo data science tools and methods.\nDiscover new data and R packages.\nDeliberate data and technical topics.\nI hope you enjoy!\nAcknowledgements\nThumbnail artwork by @allison_horst.\n\n\n",
    "preview": "posts/2018-11-05-welcome-to-piping-hot-data/tidyverse_celestial.png",
    "last_modified": "2020-10-07T20:51:39-04:00",
    "input_file": {},
    "preview_width": 2048,
    "preview_height": 2048
  }
]
